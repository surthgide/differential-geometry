\section{Prodotto diretto di gruppi di Lie}\label{es3-1}

\begin{tcolorbox}
	Dimostrare che il prodotto diretto di due gruppi di Lie è un gruppo di Lie.
\end{tcolorbox}

Consideriamo i due seguenti gruppi di Lie:

\begin{itemize}
	\item $ (G, \mu, i) $ con operazioni definite come\\
		\sbs{0.45}{%
					\map{\mu}
						{G \times G}{G}
						{(g_{1},g_{2})}{g_{1} \cdot g_{2}}
					}
			{0.45}{%
					\map{i}
						{G}{G}
						{g}{g^{-1}}
					}
		
	\item $ (H, \nu, j) $ con operazioni definite come\\
		\sbs{0.45}{%
					\map{\nu}
					{H \times H}{H}
					{(h_{1},h_{2})}{h_{1} * h_{2}}
					}
			{0.45}{%
					\map{j}
						{H}{H}
						{h}{h^{-1}}
					}	
\end{itemize}

A questo punto definiamo $ (\Omega, \sigma, k) $ il prodotto diretto dei due gruppi di Lie appena definiti, i.e.

\begin{equation}
	(\Omega, \sigma, k) \doteq (G, \mu, i) \times (H, \nu, j) = (G \times H, \mu \times \nu, i \times j)
\end{equation}

dove le operazioni di $ \Omega $ sono definite come:

\sbs{0.5}{%
			\map{\sigma}
				{\Omega \times \Omega}{\Omega}
				{(s_{1},s_{2})}{s_{1} \star s_{2}}
			}
	{0.5}{%
			\map{k}
				{\Omega}{\Omega}
				{s}{s^{-1}}
			}

Esplicitando i gruppi di Lie sottostanti, possiamo riscrivere queste operazioni come:

\map{\sigma = \mu \times \nu}
	{G \times G \times H \times H}{G \times H}
	{(g_{1},g_{2},h_{1},h_{2})}{(g_{1} \cdot g_{2},h_{1} * h_{2})}

\map{k = i \times j}
	{G \times H}{G \times H}
	{(g,h)}{(g^{-1},h^{-1})}

Il prodotto diretto conserva in $ \Omega $ le proprietà di gruppo algebrico di $ G $ e $ H $. Affinché $ \Omega $ sia un gruppo di Lie, è necessario che le operazioni $ \sigma $ e $ k $ siano lisce: per dimostrare questo, consideriamo le seguenti proiezioni tra varietà

\sbs{0.5}{%
			\map{\pi_{G}}
				{\Omega}{G}
				{s = (g,h)}{g}
			}
	{0.5}{%
			\map{\pi_{H}}
				{\Omega}{H}
				{s = (g,h)}{h}
			
			}
		
Da cui possiamo derivare i seguenti diagrammi:

\sbs{0.5}{%
			\diagr{%
					G \times G \arrow[rr, "\mu"]                                                                                         \&  \& G                                                   \\
					\&  \&                                                     \\
					\Omega \times \Omega \arrow[rr, "\sigma"] \arrow[dd, "\pi_{H} \times \pi_{H}"] \arrow[uu, "\pi_{G} \times \pi_{G}"'] \&  \& \Omega \arrow[dd, "\pi_{H}"] \arrow[uu, "\pi_{G}"'] \\
					\&  \&                                                     \\
					H \times H \arrow[rr, "\nu"]                                                                                         \&  \& H                                                  
					}
			}
	{0.5}{%
			\diagr{%
					G \arrow[rr, "i"]                                                   \&  \& G                                                   \\
					\&  \&                                                     \\
					\Omega \arrow[rr, "k"] \arrow[dd, "\pi_{H}"] \arrow[uu, "\pi_{G}"'] \&  \& \Omega \arrow[dd, "\pi_{H}"] \arrow[uu, "\pi_{G}"'] \\
					\&  \&                                                     \\
					G \arrow[rr, "j"]                                                   \&  \& H                                                  
					}
			}

Mediante le proiezioni è possibile scrivere le operazioni del gruppo $ \Omega $ come

\begin{gather}
		\sigma = (\pi_{G})^{-1} \circ \mu \circ (\pi_{G} \times \pi_{G}) %
		= (\pi_{H})^{-1} \circ \nu \circ (\pi_{H} \times \pi_{H})\\
		k = (\pi_{G})^{-1} \circ i \circ \pi_{G} %
		= (\pi_{H})^{-1} \circ j \circ \pi_{H}
\end{gather}

Siccome le proiezioni e le operazioni dei gruppi $ G $ e $ H $ sono liscie, anche le operazioni di $ \Omega $ sono lisce in quanto composizioni di applicazioni lisce; questo mostra che $ (\Omega, \sigma, k) $ è un gruppo di Lie.

%

\newpage

%

\section{Topologie sul toro}\label{es3-2}

\begin{tcolorbox}
	Siano la proiezione
	
	\map{\pi}
		{\R^{2}}{\T^{2} = \S^{1} \times \S^{1}}
		{(t,s)}{(e^{2 \pi i t},e^{2 \pi i s})}
	
	l'insieme
	
	\begin{equation}
		L = \{ (t,\alpha t) \in \R^{2} \mid \alpha \in \R \setminus \Q \}
	\end{equation}
	
	e la restrizione di $ \pi $ a $ L $, i.e.
	
	\begin{equation}
		f = \eval{\pi}_{L} : L \to \S^{1} \times \S^{1}
	\end{equation}

	Siano
	
	\begin{itemize}
		\item $ \tau_{f} $ la topologia indotta da $ f $ su $ H = \pi(L) $;
		
		\item $ \tau_{s} $ la topologia indotta dall'inclusione $ H \subset \S^{1} \times \S^{1} $
	\end{itemize}
	
	Dimostrare che $ \tau_{s} \subset \tau_{f} $.
\end{tcolorbox}

Definiamo le due topologie:

\begin{itemize}
	\item $ \tau_{s} $: $ W $ è aperto in $ H $ se $ W = U \cap H $ con $ U \subset \S^{1} \times \S^{1} $ aperto;
	
	\item $ \tau_{f} $: $ W $ è aperto in $ H $ se $ f^{-1}(W) \subset L $ è aperto in $ L $.
\end{itemize}

Sappiamo che $ f $ è un'immersione iniettiva\footnote{%
	Vedi Esempio \ref{ex:embed-torus}.%
} (non un embedding).

%

\newpage

%

\section{Esponenziale di matrice}\label{es3-3}

\begin{tcolorbox}
	Sia la matrice
	
	\begin{equation}
		X = \bmqty{ %
					0 & 1 \\
					1 & 0 %
					}
	\end{equation}
	
	Dimostrare che
	
	\begin{equation}
		e^{X} = \bmqty{ %
						\cosh(1) & \sinh(1) \\\\
						\sinh(1) & \cosh(1) %
						}
	\end{equation}
\end{tcolorbox}

Possiamo vedere che la matrice $ X $ è idempotente, i.e.

\begin{equation}
	X^{2} = \bmqty{ %
					0 & 1 \\
					1 & 0 %
					} %
			\bmqty{ %
					0 & 1 \\
					1 & 0 %
					} %
	= \bmqty{ %
				1 & 0 \\
				0 & 1 %
				} %
	= I
\end{equation}

da cui le relazioni

\begin{equation}
	\begin{cases}
		X^{2k} = I \\
		X^{2k+1} = X
	\end{cases}
	\quad k \in \N \cup \{0\}
\end{equation}

Consideriamo anche le espansioni in serie di Taylor delle seguenti due funzioni iperboliche:\\

\sbs{0.5}{%
			\begin{equation}
				\cosh(t) = \sum_{k=0}^{+\infty} \dfrac{t^{2k}}{(2k)!}
			\end{equation}
			}
	{0.5}{%
			\begin{equation}
				\sinh(t) = \sum_{k=0}^{+\infty} \dfrac{t^{2k+1}}{(2k+1)!}
			\end{equation}
			}

A questo punto, possiamo calcolare l'esponenziale di $ X $ mediante la definizione:

\begin{align}
	\begin{split}
		e^{X} &\doteq \sum_{k=0}^{+\infty} \dfrac{X^{k}}{k!} \\\\
		&= \sum_{k=0}^{+\infty} \left( \dfrac{X^{2k}}{(2k)!} + \dfrac{X^{2k+1}}{(2k+1)!} \right) \\\\
		&= \sum_{k=0}^{+\infty} \left( \dfrac{(1)^{2k}}{(2k)!} \, I \right) + \sum_{k=0}^{+\infty} \left( \dfrac{(1)^{2k+1}}{(2k+1)!} \, X \right) \\\\
		&= \sum_{k=0}^{+\infty} \left( \dfrac{(1)^{2k}}{(2k)!} \right) I + \sum_{k=0}^{+\infty} \left( \dfrac{(1)^{2k+1}}{(2k+1)!} \right) X \\\\
		&= \cosh(1) \, I + \sinh(1) \, X \\\\
		&= \bmqty{ %
					\cosh(1) & \sinh(1) \\\\
					\sinh(1) & \cosh(1) %
					}
	\end{split}
\end{align}

dove nel quarto passaggio abbiamo usato la proprietà delle serie convergenti

\begin{equation}
	\sum_{n=0}^{+\infty} a s_{n} = a \sum_{n=0}^{+\infty} s_{n}
\end{equation}

in quanto $ M_{n}(\R) $ è uno spazio di Banach, quindi completo.

%

\newpage

%

\section{Esponenziale di somma di matrici}\label{es3-4}

\begin{tcolorbox}
	Trovare due matrici $ A $ e $ B $ tali che
	
	\begin{equation}
		e^{A+B} \neq e^{A} e^{B}
	\end{equation}
\end{tcolorbox}

Prese due matrici $ A,B \in M_{n}(\K) $ con $ \K = \R, \C $, vale la proprietà

\begin{equation}
	e^{A+B} = e^{A} e^{B} \qcomma [A,B] = 0
\end{equation}

Un esempio di matrici che non rispettano questa proprietà può essere:

\sbs{0.5}{%
			\begin{equation}
				A = \bmqty{ %
							0 & 1 \\
							1 & 0 %
							}
			\end{equation}
			}
	{0.5}{%
			\begin{equation}
				B = \bmqty{ %
							0 & 1 \\
							0 & 0 %
							}
			\end{equation}
			}

in quanto

\begin{equation}
	[A,B] = %
	\bmqty{ 0 & 1 \\ 1 & 0 } \bmqty{ 0 & 1 \\ 0 & 0 } - \bmqty{ 0 & 1 \\ 0 & 0 }  \bmqty{ 0 & 1 \\ 1 & 0 } %
	= \bmqty{ -1 & 0 \\ 0 & 1 } %
	\neq 0
\end{equation}

%

\newpage

%

\section{Matrici unitarie come insieme compatto}\label{es3-5}

\begin{tcolorbox}
	Dimostrare che il gruppo unitario $ U(n) $ è compatto per ogni $ n \geqslant 1 $.
\end{tcolorbox}

Per dimostrare che $ U(n) \subset GL_{n}(\C) $ sia compatto, è necessario dimostrare che sia chiuso e limitato in $ GL_{n}(\C) $.\\
È chiuso perché preimmagine di $ I \in GL_{n}(\C) $ tramite l'applicazione continua

\map{F}
	{GL_{n}(\C)}{GL_{n}(\C)}
	{A}{A^{*} A}


Mentre è limitato in quanto le colonne delle matrici di $ U(n) $ hanno norma unitaria e quindi la somma delle colonne è limitata dalla dimensione n delle matrici.\\
Svolgendo il prodotto matriciale nella definizione di $ U(n) $

\begin{equation}
	A^{*} A = %
	\bmqty{ %
		\bar{a}_{11} & \bar{a}_{21} & \cdots & \bar{a}_{n1} \\ %
		\bar{a}_{12} & \bar{a}_{22} & \cdots & \bar{a}_{n2} \\ %
		\vdots & \vdots & \ddots & \vdots \\ %
		\bar{a}_{1n} & \bar{a}_{2n} & \cdots & \bar{a}_{nn}
	}
	\bmqty{ %
		a_{11} & a_{12} & \cdots & a_{1n} \\ %
		a_{21} & a_{22} & \cdots& a_{2n} \\ %
		\vdots & \vdots & \ddots & \vdots \\ %
		a_{n1} & a_{n2} & \cdots & a_{nn}
	}
\end{equation}

se consideriamo solo la prima entrata della matrice prodotto, otteniamo

\begin{equation}
	\abs{a_{11}}^{2} + \abs{a_{21}}^{2} + \cdots + \abs{a_{n1}}^{2} = 1
\end{equation}

e così per il resto degli elementi nella diagonale, mentre tutti gli altri prodotti hermitiani tra il resto delle colonne è nullo.\\
Questo implica che, considerata la norma per matrici complesse

\map{\norm{}}
	{M_{n}(\C)}{\R}
	{X = [x_{ij}]_{i,j=1,\dots,n}}{\left( \sum_{i,j=1}^{n} \abs{x_{ij}}^{2} \right)^{1/2}}

vale per le matrici unitarie

\begin{equation}
	\norm{A} \leqslant n \qcomma \forall A \in U(n)
\end{equation}

%

\newpage

%

\section{Proprietà componente connessa $ G_{0} $ di un gruppo di Lie}\label{es3-6}

\begin{tcolorbox}
	Siano $ G $ un gruppo di Lie e $ G_{0} $ la componente connessa di $ G $ che contiene $ e $ (elemento neutro di $ G $). Se $ \mu $ e $ i $ denotano rispettivamente la moltiplicazione e l'inversione in $ G $, provare che:
	
	\begin{enumerate}
		\item $ \mu(\{g\} \times G_{0}) \subset G_{0} $ per qualsiasi $ g \in G_{0} $;
		
		\item $ i(G_{0}) \subset G_{0} $;
		
		\item $ G_{0} $ è un sottoinsieme aperto di $ G $;
		
		\item $ G_{0} $ è un sottogruppo di Lie di $ G $.
	\end{enumerate}
\end{tcolorbox}

\paragraph{1)}

Considerando un elemento $ g \in G $ e la traslazione a sinistra

\map{L_{g}}
	{G}{G}
	{h}{g h}

possiamo scrivere

\begin{equation}
	L_{g}(G_{0}) = \mu(\{g\} \times G_{0})
\end{equation}

Sappiamo che la traslazione a sinistra è un diffeomorfismo\footnote{%
	Vedi Sezione \ref{sec:lie-groups}.%
}, dunque anche continua: prendendo un qualunque elemento $ g \in G_{0} $, questo è collegato all'identità tramite

\begin{equation}
	L_{g}(e) = e g = g \in G_{0} \qcomma \forall g \in G_{0}
\end{equation}

Questo dimostra che $ L_{g}(G_{0}) $ sia connesso (per archi) e quindi che

\begin{equation}
	L_{g}(G_{0}) = \mu(\{g\} \times G_{0}) \subset G_{0} \qcomma \forall g \in G_{0}
\end{equation}

in quanto $ G_{0} $ è componente connessa di $ G $.\\
L'ultima condizione può essere anche scritta come $ \mu(G_{0} \times G_{0}) \subset G_{0} $.

\paragraph{2)}

Essendo l'inversione $ i : G \to G $ un omeomorfismo (bigezione continua con inversa continua), abbiamo che $ i(G_{0}) $ è connesso. Inoltre, abbiamo che l'immagine di $ G_{0} $ tramite l'inversione contiene l'elemento neutro, i.e.

\begin{equation}
	i(G_{0}) \ni e \, \because \, i(e) = e
\end{equation}

A questo punto, siccome $ i(G_{0}) $ è connesso, contiene $ e \in G_{0} $ e $ G_{0} $ è una componente connessa di $ G $, possiamo scrivere $ i(G_{0}) \subset G_{0} $.

\paragraph{3)}

Vedi Proposizione \ref{prop:conn-comp-open}, poiché $ G $ è localmente euclideo in quanto varietà differenziabile.

\paragraph{4)}

Siccome per il punto precedente, $ G_{0} \subset G $ è aperto in $ G $, la componente connessa $ G_{0} $ è una sottovarietà di $ G $. Tramite la Proposizione \ref{prop:lie-group-cond}, è necessario dunque mostrare che $ G_{0} < G $ perché $ G_{0} $ sia sottogruppo di Lie di $ G $: questo è immediatamente verificato dai primi due punti, i.e.

\begin{equation}
	\begin{cases}
		\mu(G_{0} \times G_{0}) \subset G_{0} \\
		i(G_{0}) \subset G_{0}
	\end{cases} %
	\implies %
	G_{0} < G
\end{equation}

dove moltiplicazione e inversione di $ G $ inducono le operazioni su $ G_{0} $:

\sbs{0.5}{%
			\map{\mu_{0}}
				{G_{0} \times G_{0}}{G_{0}}
				{(g,h)}{g h}
			}
	{0.5}{%
			\map{i_{0}}
				{G_{0}}{G_{0}}
				{g}{g^{-1}}
			}

%

\newpage

%

\section{Diffeomorfismo $ SO(2) \simeq \S^{1} $}\label{BONUS3-1}

\begin{tcolorbox}
	Verificare che $ SO(2) $ sia diffeomorfo a $ \S^{1} $.
\end{tcolorbox}

Dalle definizioni degli spazi in esame, possiamo derivare le seguenti definizioni alternative:

\begin{align}
	\begin{split}
		SO(2) &= \{ X \in M_{2}(\R) \mid X^{T} X = I \, \wedge \, \det(X) = 1 \} \subset O(2) \subset GL_{2}(\R) \subset M_{2}(\R) \\
		&= \left\{ X = \bmqty{ a & b \\ -b & a } \in M_{2}(\R) \st \det(X) = a^{2} + b^{2} = 1 \right\} \\
		&= \left\{ \bmqty{ \cos(\theta) & \sin(\theta) \\ -\sin(\theta) & \cos(\theta) } \in M_{2}(\R) \st \theta \in [0,2\pi) \subset \R \right\}
	\end{split}
\end{align}

\begin{align}
	\begin{split}
		\S^{1} &= \{ (x,y) \in \R^{2} \mid x^{2} + y^{2} = 1 \} \subset \R^{2} \\
		&= \{ z \in \C \mid \abs{z} = 1 \} \subset \C = \R^{2} \\
		&= \{ e^{i \theta} \in \C \mid \theta \in [0,2\pi) \subset \R \}
	\end{split}
\end{align}

Consideriamo ora l'applicazione

\map{\phi}
	{\S^{1}}{SO(2)}
	{e^{i \theta}}{\bmqty{ \cos(\theta) & \sin(\theta) \\ -\sin(\theta) & \cos(\theta) }}

la quale è liscia in quanto composizione delle applicazioni lisce $ \phi = h \circ g \circ f $ definite come:

\map{f}
	{\S^{1}}{\R^{2}}
	{e^{i \theta}}{(\cos(\theta), \sin(\theta))}

\map{g}
	{\R^{2}}{\R^{4}}
	{(\cos(\theta), \sin(\theta))}{(\cos(\theta), \sin(\theta), -\sin(\theta), \cos(\theta))}

\map{h}
	{\R^{4}}{SO(2)}
	{(\cos(\theta), \sin(\theta), -\sin(\theta), \cos(\theta))}
	{\bmqty{ \cos(\theta) & \sin(\theta) \\ -\sin(\theta) & \cos(\theta) }}

A questo punto, definiamo le applicazioni

\sbs{0.5}{%
			\map{\psi}
				{M_{2}(\R)}{\S^{1}}
				{\bmqty{ a & b \\ c & d }}{a + i b}
			}
	{0.5}{%
			\map{i}
				{SO(2)}{M_{2}(\R)}
				{A}{A}
			}

le quali sono lisce perché rispettivamente $ \psi $ è lineare, e valgono le condizioni\footnote{%
	Vedi Proposizione \ref{prop:subman-incl-immersion}.%
}

\begin{equation}
	SO(2) \subset M_{2}(\R) \text{ sottovarietà\footnotemark} %
	\iff %
	i \text{ immersione} %
	\implies %
	i \in C^{\infty}(SO(2))
\end{equation}
\footnotetext{%
	L'insieme $ SO(n) $ è aperto in $ O(n) $ (vedi Sottosezione \ref{ssec:o-n-subgroup-lie-glnr}), che è sottovarietà di $ GL_{n}(\R) $, il quale a sua volta è aperto in $ M_{n}(\R) $: questo rende $ SO(n) $ sottovarietà di $ M_{n}(\R) $.%
}

Se componiamo le applicazioni appena definite, otteniamo

\map{\phi^{-1} \doteq \psi \circ i = \eval{\psi}_{SO(2)}}
	{SO(2)}{\S^{1}}
	{\bmqty{ \cos(\theta) & \sin(\theta) \\ -\sin(\theta) & \cos(\theta) }}
	{\cos(\theta) + i \sin(\theta) = e^{i \theta}}

la quale è liscia perché composizione di applicazioni lisce e inoltre è inversa di $ \phi $. Avendo trovato un'applicazione liscia, invertibile, e con inversa liscia tra i due spazi, abbiamo dimostrato che i due sono diffeomorfi, i.e.

\begin{equation}
	\begin{cases}
		\phi \in C^{\infty}(\S^{1}) \\\\
		\begin{cases}
			\phi \circ \phi^{-1} = \id_{\S^{1}} \\
			\phi^{-1} \circ \phi = \id_{SO(2)}
		\end{cases} \\\\
		\phi^{-1} \in C^{\infty}(SO(2))
	\end{cases}
	\implies %
	SO(2) \simeq \S^{1}
\end{equation}

%

\newpage

%

\section{Diffeomorfismo $ SU(2) \simeq \S^{3} $}\label{BONUS3-2}

\begin{tcolorbox}
	Verificare che $ SU(2) $ sia diffeomorfo a $ \S^{3} $.
\end{tcolorbox}

Dalle definizioni degli spazi in esame, possiamo derivare le seguenti definizioni alternative:

\begin{align}
	\begin{split}
		SU(2) &= \{ A \in M_{2}(\C) \mid A^{*} A = I \, \wedge \, \det(A) = 1 \} \subset U(2) \subset GL_{2}(\C) \subset M_{2}(\C) \\
		&= \left\{ \bmqty{ \alpha & - \bar{\beta} \\ \beta & \bar{\alpha} } \in M_{2}(\C) \st \alpha, \beta \in \C^{2}, \, \det(A) = \abs{\alpha}^{2} + \abs{\beta}^{2} = 1 \right\}
	\end{split}
\end{align}

\begin{align}
	\begin{split}
		\S^{1} &= \{ (a,b,c,d) \in \R^{4} \mid a^{2} + b^{2} + c^{2} + d^{2} = 1 \} \subset \R^{4} \\
		&= \{ (\alpha, \beta) \in \C^{2} \mid \abs{\alpha}^{2} + \abs{\beta}^{2} = 1 \} \subset \C^{2} = \R^{4}
	\end{split}
\end{align}

dove, per legare la prima definizione di $ \S^{3} $ alla seconda, si può considerare l'identificazione

\begin{equation}
	\begin{cases}
		\alpha = a + i b \\
		\beta = c + i d
	\end{cases} %
	\qquad a,b,c,d \in \R
\end{equation}

Analogamente all'esercizio precedente, possiamo considerare l'applicazione liscia, invertibile e con inversa liscia:

\map{\phi}
	{\S^{3}}{SU(2)}
	{(\alpha, \beta)}{\bmqty{ \alpha & - \bar{\beta} \\ \beta & \bar{\alpha} }}

Questa rende dunque i due spazi diffeomorfi, i.e. $ SU(2) \simeq \S^{3} $.

%

\newpage

%

\section{Differenziale moltiplicazione gruppo di Lie}\label{es3-7}

\begin{tcolorbox}
	Sia $ G $ un gruppo di Lie con moltiplicazione $ \mu : G \times G \to G $. Dimostrare che
	
	\begin{equation}
		\mu_{*(a,b)}(X_{a},Y_{b}) = (R_{b})_{*a}(X_{a}) + (L_{a})_{*b}(Y_{b}) %
		\qcomma \forall (a,b) \in G \times G, \, \forall X_{a} \in T_{a}(G), \, \forall Y_{b} \in T_{b}(G)
	\end{equation}
	
	dove $ L_{a} $ (risp. $ R_{b} $) denota la traslazione a sinistra (risp. a destra) associata ad $ a $ (risp. $ b $).
\end{tcolorbox}

Siccome il differenziale è un'applicazione lineare, possiamo scrivere\footnote{%
	Vedi Paragrafo \ref{par:differ-prod-inv-lie}.%
}

\begin{equation}
	\mu_{*(a,b)}(X_{a},Y_{b}) = \mu_{*(a,b)}(X_{a},0) + \mu_{*(a,b)}(0,Y_{b})
\end{equation}

Consideriamo ora le seguenti curve lisce:

\sbs{0.5}{%
			\begin{equation}
				\begin{cases}
					c : (- \varepsilon, \varepsilon) \to G \\
					c(0) = a \\
					c'(0) = X_{a}
				\end{cases}
			\end{equation}
			}
	{0.5}{%
			\begin{equation}
				\begin{cases}
					d : (- \varepsilon, \varepsilon) \to G \\
					d(0) = b \\
					d'(0) = Y_{b}
				\end{cases}
			\end{equation}
			}

\sbs{0.5}{%
			\begin{equation}
				\begin{cases}
					\gamma \doteq (c(t), b) \\
					\gamma(0) = (a,b) \\
					\gamma'(0) = (X_{a}, 0)
				\end{cases}
			\end{equation}
			}
	{0.5}{%
			\begin{equation}
				\begin{cases}
					\eta \doteq (a, d(t)) \\
					\eta(0) = (a,b) \\
					\eta'(0) = (0, Y_{b})
				\end{cases}
			\end{equation}
			}

Queste ci permettono di calcolare i differenziale delle traslazioni a destra e sinistra, e della moltiplicazione:

\begin{gather}
	(R_{b})_{*a}(X_{a}) = \eval{ \dv{t} }_{0} R_{b}(c(t)) %
	= \eval{ \dv{t} }_{0} (c(t) \, b) %
	= c'(0) \, b %
	= X_{a} \, b \\
	%
	(L_{a})_{*b}(Y_{b}) = \eval{ \dv{t} }_{0} L_{a}(d(t)) %
	= \eval{ \dv{t} }_{0} (a \, d(t)) %
	= a \, d'(0) %
	= a \, Y_{b}
\end{gather}

\begin{gather}
	\mu_{*(a,b)}(X_{a}, 0) = \dot{ (\mu \circ \gamma) }(0) %
	= \mu'(c(t), b)(0) %
	= (c(t) \, b)'(0) %
	= c'(0) \, b %
	= X_{a} \, b \\
	%
	\mu_{*(a,b)}(0, Y_{b}) = \dot{ (\mu \circ \eta) }(0) %
	= \mu'(a, d(t))(0) %
	= (a \, d(t))'(0) %
	= a \, d'(0) %
	= a \, Y_{b}
\end{gather}

dunque

\begin{equation}
	\mu_{*(a,b)}(X_{a},Y_{b}) = (R_{b})_{*a}(X_{a}) + (L_{a})_{*b}(Y_{b}) %
	= X_{a} \, b + a \, Y_{b}
\end{equation}

%

\newpage

%

\section{Differenziale inversione gruppo di Lie}\label{es3-8}

\begin{tcolorbox}
	Sia $ G $ un gruppo di Lie con inversione $ i : G \to G $. Dimostrare che
	
	\begin{equation}
		i_{*a}(Y_{a}) = -(R_{a^{-1}})_{*e}(L_{a^{-1}})_{*a} (Y_{a}) %
		\qcomma \forall a \in G, \, \forall Y_{a} \in T_{a}(G)
	\end{equation}
\end{tcolorbox}

Per l'inversione, vale la seguente proprietà:

\begin{equation}
	R_{a} \circ i = i \circ L_{a^{-1}} \qcomma \forall a \in G
\end{equation}

Moltiplicando entrambi i membri a sinistra per l'inversa della traslazione a destra, i.e.

\begin{equation}
	(R_{a})^{-1} = R_{a^{-1}} \qcomma \forall a \in G
\end{equation}

otteniamo

\begin{equation}
	i = R_{a^{-1}} \circ i \circ L_{a^{-1}} \qcomma \forall a \in G
\end{equation}

Differenziando quest'espressione in una qualsiasi elemento $ a \in G $, possiamo scrivere

\begin{align}
	\begin{split}
		i_{*a} &= (R_{a^{-1}} \circ i \circ L_{a^{-1}})_{*a} \\
		&= (R_{a^{-1}})_{*i(e)} \circ i_{*L_{a^{-1}}(a)} \circ (L_{a^{-1}})_{*a} \\
		&= (R_{a^{-1}})_{*e} \circ i_{*e} \circ (L_{a^{-1}})_{*a}
	\end{split}
\end{align}

dove abbiamo utilizzato che

\begin{gather}
	i(e) = e^{-1} = e \\
	L_{a^{-1}}(a) = a^{-1} a = e
\end{gather}

Dal Paragrafo \ref{par:differ-prod-inv-lie}, sappiamo che

\begin{equation}
	i_{*e} (Y_{e}) = - Y_{e}
\end{equation}

possiamo dunque applicare il differenziale a un qualsiasi vettore dello spazio tangente $ Y_{a} \in T_{a}(G) $, ottenendo

\begin{align}
	\begin{split}
		i_{*a}(Y_{a}) &= (R_{a^{-1}})_{*e} \circ i_{*e} \circ (L_{a^{-1}})_{*a} \\
		&= (- (R_{a^{-1}})_{*e} \circ (L_{a^{-1}})_{*a}) (Y_{a}) \\
		&= - (R_{a^{-1}})_{*e} (L_{a^{-1}})_{*a} (Y_{a})
	\end{split}
\end{align}

%

\newpage

%

\section{Commutatore matriciale per algebre di Lie}\label{es3-9}

\begin{tcolorbox}
	Verificare che il commutatore tra matrici
	
	\begin{equation}
		[A,B] = AB - BA
	\end{equation}
	
	definisce un'algebra di Lie sullo spazio tangente all'identità dei gruppi: $ O(n) $, $ SO(n) $, $ U(n) $, $ SU(n) $, $ SL_{n}(\R) $, $ SL_{n}(\C) $.
\end{tcolorbox}

Dal Corollario \ref{cor:incl-alg-lie-subg}, sappiamo che il commutatore dei sottogruppi matriciali di $ GL_{n}(\K) $ è dato dal commutatore standard

\begin{equation}
	[A,B] = AB - BA
\end{equation}

in quanto il commutatore del gruppo lineare induce il commutatore nei suo sottogruppi tramite il differenziale dell'inclusione.\\
Consideriamo ora i seguenti insiemi

\begin{equation}
	\begin{cases}
		S^{-}_{n}(\K) = \{ X \in M_{n}(\K) \mid X^{T} = - X \} & \text{ (antisimmetriche)} \\
		H^{-}_{n} = \{ X \in M_{n}(\C) \mid X^{*} = - X \} & \text{ (antihermitiane)} \\
		T^{0}_{n}(\K) = \{ X \in M_{n}(\K) \mid \tr(X) = 0 \} & \text{ (traccia nulla)}
	\end{cases} %
	\qquad \K = \R, \C
\end{equation}

i quali permettono di scrivere le algebre di Lie relative ai gruppi di Lie in esame nel seguente modo:

\begin{align}
	O(n) &\longrightarrow \mathfrak{o}(n) = (S^{-}_{n}(\R),[,]) \\
	SO(n) &\longrightarrow \so(n) = (S^{-}_{n}(\R) \cap T^{0}_{n}(\R),[,]) \\
	U(n) &\longrightarrow \mathfrak{u}(n) = (H^{-}_{n},[,]) \\
	SU(n) &\longrightarrow \su(n) = (H^{-}_{n} \cap T^{0}_{n}(\C),[,]) \\
	SL_{n}(\R) &\longrightarrow \mathfrak{sl}(n,\R) = (T^{0}_{n}(\R),[,]) \\
	SL_{n}(\C) &\longrightarrow \mathfrak{sl}(n,\C) = (T^{0}_{n}(\C),[,])
\end{align}

dove l'insieme ambiente delle algebre è dato dallo spazio tangente all'identità del gruppo relativo.\\
Possiamo ora verificare che le condizioni valide per gli elementi dello spazio tangente all'unità dei vari gruppi valgano anche per i commutatori definiti sulla loro algebra. In particolare, dobbiamo verificare che i commutatori di matrici antisimmetriche e di matrici antihermitiane siano rispettivamente antisimmetrici e antihermitiani, e che la traccia di un commutatore di matrici a traccia nulla sia anch'essa nulla:

\begin{gather}
	[X,Y]^{T} = (X Y - Y X)^{T} = Y^{T} X^{T} - X^{T} Y^{T} = Y X - X Y = - [X,Y] %
	\qcomma \forall X,Y \in S^{-}_{n}(\K) \\
	[X,Y]^{*} = (X Y - Y X)^{*} = Y^{*} X^{*} - X^{*} Y^{*} = Y X - X Y = - [X,Y] %
	\qcomma \forall X,Y \in H^{-}_{n} \\
	\tr([X,Y]) = \tr(X Y - Y X) = \tr(X Y) - \tr(Y X) = \tr(X Y) - \tr(X Y) = 0
\end{gather}

dove abbiamo usato la proprietà

\begin{equation}
	\tr(A B) = \tr(B A) \qcomma \forall A,B \in M_{n}(\K)
\end{equation}

A questo punto i commutatori delle algebre in esame appartengono ai rispettivi spazi tangenti all'unità dei gruppi.

%

\newpage

%

\section{Esponenziale per gruppi di Lie}\label{es3-10}

\begin{tcolorbox}
	Verificare che l'esponenziale di una matrice definisce un'applicazione
	
	\map{e}
		{T_{I}(G)}{G}
		{A}{e^{A}}
	
	per i gruppi di Lie: $ GL_{n}(\R) $, $ GL_{n}(\C) $, $ SL_{n}(\R) $, $ SL_{n}(\C) $, $ O(n) $, $ SO(n) $, $ U(n) $, $ SU(n) $
\end{tcolorbox}

Consideriamo i seguenti insiemi

\begin{equation}
	\begin{cases}
		S^{-}_{n}(\K) = \{ A \in M_{n}(\K) \mid A^{T} = - A \} & \text{ (antisimmetriche)} \\
		H^{-}_{n} = \{ A \in M_{n}(\C) \mid A^{*} = - A \} & \text{ (antihermitiane)} \\
		T^{0}_{n}(\K) = \{ A \in M_{n}(\K) \mid \tr(A) = 0 \} & \text{ (traccia nulla)}
	\end{cases} %
	\qquad \K = \R, \C
\end{equation}

i quali permettono di scrivere gli spazi tangenti ai gruppi di Lie in esame nel seguente modo:

\begin{align}
	T_{I}(GL_{n}(\K)) &= M_{n}(\K) \\
	T_{I}(SL_{n}(\K)) &= T^{0}_{n}(\K) \\
	T_{I}(O(n)) &= S^{-}_{n}(\R) \\
	T_{I}(SO(n)) &= S^{-}_{n}(\R) \cap T^{0}_{n}(\R) \\
	T_{I}(U(n)) &= H^{-}_{n} \\
	T_{I}(SU(n)) &= H^{-}_{n} \cap T^{0}_{n}(\C)
\end{align}

Calcoliamo ora il trasposto e il coniugato dell'esponenziale di una matrice $ A \in M_{n}(\K) $ tramite la definizione di esponenziale di matrice:

\begin{gather}
	\left( e^{A} \right)^{T} = \left( \sum_{+ \infty}^{i=1} \dfrac{A^{i}}{i !} \right)^{T} %
	= \sum_{+ \infty}^{i=1} \dfrac{(A^{i})^{T}}{i !} %
	= \sum_{+ \infty}^{i=1} \dfrac{\left( A^{T} \right)^{i}}{i !} %
	= e^{\left( A^{T} \right)} \\
	\nonumber \\
	\left( e^{A} \right)^{*} = \left( \sum_{+ \infty}^{i=1} \dfrac{A^{i}}{i !} \right)^{*} %
	= \sum_{+ \infty}^{i=1} \dfrac{(A^{i})^{*}}{i !} %
	= \sum_{+ \infty}^{i=1} \dfrac{\left( A^{*} \right)^{i}}{i !} %
	= e^{\left( A^{*} \right)}
\end{gather}

Consideriamo infine le seguenti implicazioni:

\begin{gather}
	A \in T^{0}_{n}(\K) %
	\implies \det(e^{A}) = e^{\tr(A)} = e^{0} = 1 %
	\implies e^{A} \in SL_{n}(\K) \\
	%
	A \in M_{n}(\K) %
	\implies \det(e^{A}) = e^{\tr(A)} \neq 0 %
	\implies e^{A} \in GL_{n}(\K) \\
	%
	A \in S^{-}_{n}(\R) %
	\implies e^{A} \left( e^{A} \right)^{T} = e^{A} e^{\left( A^{T} \right)} = e^{A} e^{-A} = e^{0} = I %
	\implies e^{A} \in O(n) \\
	%
	A \in H^{-}_{n} %
	\implies e^{A} \left( e^{A} \right)^{*} = e^{A} e^{\left( A^{*} \right)} = e^{A} e^{-A} = e^{0} = I %
	\implies e^{A} \in U(n)
\end{gather}

dove per la prima abbiamo usato la Proposizione \ref{prop:det-exp-tr} e per la seconda il Corollario \ref{cor:det-exp-gl}.\\
A questo punto, possiamo usare questi ragionamenti per verificare che l'esponenziale di matrice definisca un'applicazione dallo spazio tangente al gruppo matriciale al gruppo stesso:

\begin{gather}
	A \in T_{I}(GL_{n}(\K)) = M_{n}(\K) %
	\implies e^{A} \in GL_{n}(\K) \\
	%
	A \in T_{I}(SL_{n}(\K)) = T^{0}_{n}(\K) %
	\implies e^{A} \in SL_{n}(\K) \\
	%
	A \in T_{I}(O(n)) = S^{-}_{n}(\R) %
	\implies e^{A} \in O(n) \\
	%
	A \in T_{I}(SO(n)) = S^{-}_{n}(\R) \cap T^{0}_{n}(\R) %
	\implies e^{A} \in O(n) \cap SL_{n}(\R) = SO(n) \\
	%
	A \in T_{I}(U(n)) = H^{-}_{n} %
	\implies e^{A} \in U(n) \\
	%
	A \in T_{I}(SU(n)) = H^{-}_{n} \cap T^{0}_{n}(\C) %
	\implies e^{A} \in U(n) \cap SL_{n}(\C) = SU(n)
\end{gather}

%

\newpage

%

\section{Algebra di Lie di prodotto diretto di gruppi di Lie}\label{es3-11}

\begin{tcolorbox}
	Sia $ G = G_{1} \times \cdots \times G_{s} $ il prodotto diretto di gruppi di Lie. Dimostrare che l'algebra di Lie di $ G $ è isomorfa alla somma diretta delle algebre di Lie dei $ G_{i} $ con $ i=1,\dots,s $.
\end{tcolorbox}

% https://math.stackexchange.com/questions/3724626/lieg-times-h-cong-lieg-oplus-lieh

In notazione, dobbiamo dimostrare la seguente implicazione per gruppi di Lie $ G_{i} $

\begin{equation}
	\bigoplus_{i=1}^{s} Lie(G_{i}) \stackrel{iso}{\simeq} Lie \left( \prod_{i=1}^{s} G_{i} \right) %
	\qcomma \forall s \in \N
\end{equation}

Semplifichiamo il problema al caso di due gruppi nel seguente modo:

\begin{equation}
	Lie(G) \oplus Lie(H) \stackrel{iso}{\simeq} Lie(G \times H) %
	\qq{con} %
	H = \bigoplus_{i=1}^{s-1} G_{i}
\end{equation}

L'applicazione

\map{\psi}
	{Lie(G) \oplus Lie(H)}{Lie(G \times H)}
	{(\xi, \eta)}{\xi \oplus \eta}

è un isomorfismo di algebre di Lie se è un omomorfismo di algebre di Lie biunivoco e invertibile; l'immagine $ \xi \oplus \eta $ è data da

\map{\xi \oplus \eta}
	{G \times H}{T(G \times H)}
	{(g,h)}{(\xi \oplus \eta)_{(g,h)} \in T_{(g,h)}(G \times H)}

definita a sua volta dall'isomorfismo\footnote{%
	Vedi Esercizio \ref{es2-11}.%
}

\map{f_{(g,h)}}
	{T_{(g,h)}(G \times H)}{T_{g}(G) \times T_{h}(H)}
	{(\xi \oplus \eta)_{(g,h)}}
	{ %
		\left( (\pi_{G})_{*g} ((\xi \oplus \eta)_{(g,h)}), (\pi_{H})_{*h} ((\xi \oplus \eta)_{(g,h)}) \right) = (\xi_{g}, \eta_{h})
	}

con le proiezioni e i loro differenziali

\sbs{0.5}{%
			\map{\pi_{G}}
				{G \times H}{G}
				{(g,h)}{g}
				
			\map{(\pi_{G})_{*g}}
				{T_{(g,h)}(G \times H)}{T_{g}(G)}
				{(\xi \oplus \eta)_{(g,h)}}{\xi_{g}}
			}
	{0.5}{%
			\map{\pi_{H}}
				{G \times H}{H}
				{(g,h)}{h}
				
			\map{(\pi_{H})_{*h}}
				{T_{(g,h)}(G \times H)}{T_{h}(H)}
				{(\xi \oplus \eta)_{(g,h)}}{\eta_{h}}
			}

Consideriamo ora l'applicazione

\map{\phi}
	{\mathfrak{X}(G) \oplus \mathfrak{X}(H)}{\mathfrak{X}(G \times H)}
	{(X,Y)}{X \oplus Y}

dove $ X \oplus Y $ è definita analogamente a $ \xi \oplus \eta $ e $ \mathfrak{X}(G) \doteq (\chi(G), [,]) $ è l'algebra di Lie dei campi di vettori lisci su $ G $ con il commutatore tra campi di vettori definito come

\begin{equation}
	[X,Y] = X Y - Y X \qcomma X, Y \in \chi(G)
\end{equation}

da cui l'algebra di Lie

\begin{equation}
	\mathfrak{X}(G) \oplus \mathfrak{X}(H) = (\chi(G) \times \chi(H),[,])
\end{equation}

con il commutatore di quest'ultima algebra definito come

\map{[,]}
	{\chi(G) \times \chi(H) \times \chi(G) \times \chi(H)}{\chi(G) \times \chi(H)}
	{(X_{1},Y_{1},X_{2},Y_{2})}
	{[(X_{1},Y_{1}),(X_{2},Y_{2})] \doteq \left( [X_{1},X_{2}], [Y_{1},Y_{2}] \right)}

Questa applicazione è un omomorfismo di algebre di Lie in quanto

\begin{align}
	\begin{split}
		\phi \left( [(X_{1},Y_{1}),(X_{2},Y_{2})] \right) &\doteq \phi \left( [X_{1},X_{2}], [Y_{1},Y_{2}] \right) \\
		&= [X_{1},X_{2}] \oplus [Y_{1},Y_{2}] \\
		&= [X_{1} \oplus Y_{1}, X_{2} \oplus Y_{2}] \\
		&= \left[ \phi(X_{1}, Y_{1}), \phi(X_{2}, Y_{2}) \right]
	\end{split}
\end{align}

dunque

\begin{equation}
	\mathfrak{X}(G) \oplus \mathfrak{X}(H) \stackrel{iso}{\simeq} \mathfrak{X}(G \times H)
\end{equation}

A questo punto, siccome

\begin{equation}
	Lie(G) = (T_{e}(G),[,]) \stackrel{iso}{\simeq} (L(G),[,]) < (\chi(G),[,]) = \mathfrak{X}(G) %
	\; \because \; %
	\begin{cases}
		T_{e}(G) \stackrel{iso}{\simeq} L(G) \\
		L(G) \subset \chi(G)
	\end{cases}
\end{equation}

possiamo considerare la restrizione di $ \phi $ alle algebre di Lie di

\begin{equation}
	\eval{\phi}_{Lie(G) \oplus Lie(H)} : Lie(G) \oplus Lie(H) \to \mathfrak{X}(G \times H)
\end{equation}

Dal momento che $ \phi $ è una bigezione in quanto omomorfismo ed è invertibile poiché le dimensioni di dominio e codominio sono identiche, i.e.

\begin{equation}
	\dim(Lie(G) \oplus Lie(H)) = \dim(\mathfrak{X}(G) \oplus \mathfrak{X}(H)) %
	= \dim(\mathfrak{X}(G \times H)) %
	= \dim(Lie(G \times H))
\end{equation}

allora $ \psi $, essendo una restrizione di $ \phi $, deve essere solo definita perché sia un isomorfismo, i.e.

\begin{equation}
	\psi(Lie(G) \oplus Lie(H)) \subset Lie(G \times H)
\end{equation}

in altre parole

\begin{gather}
	\xi \oplus \eta \in (L(G \times H),[,]) %
	\stackrel{iso}{\simeq} (T_{(e,e)}(G \times H),[,]) %
	= Lie(G \times H) %
	\qcomma \forall (\xi,\eta) \in Lie(G) \oplus Lie(H)
\end{gather}

Per verificare questo, ricordiamo la seguente definizione di campi di vettori invarianti a sinistra:

\begin{equation}
	(L_{g})_{*h}(X_{h}) = X_{L_{g}(h)} = X_{gh} \qcomma \forall X \in L(G)
\end{equation}

Applicando quindi il differenziale della traslazione a sinistra, possiamo scrivere

\begin{align}
	\begin{split}
		(L_{g_{1}} \times L_{h_{1}})_{*(g_{2},h_{2})} \left( (\xi \oplus \eta)_{(g_{2},h_{2})} \right) &= \left( (L_{g_{1}} \times L_{h_{1}})_{*(g_{2},h_{2})} \circ (f_{(g,h)})^{-1} \right) \left( \xi_{g_{2}}, \eta_{h_{2}} \right) \\
		&= \left( (f_{(g_{1} g_{2}, h_{1} h_{2})})^{-1} \circ f_{(g_{1} g_{2}, h_{1} h_{2})} \circ (L_{g_{1}} \times L_{h_{1}})_{*(g_{2},h_{2})} \circ (f_{(g,h)})^{-1} \right) \left( \xi_{g_{2}}, \eta_{h_{2}} \right) \\
		&= \left( (f_{(g_{1} g_{2}, h_{1} h_{2})})^{-1} \circ \left( (L_{g_{1}})_{*g_{2}} \times (L_{h_{1}})_{*h_{2}} \right) \right) \left( \xi_{g_{2}}, \eta_{h_{2}} \right) \\
		&= (f_{(g_{1} g_{2}, h_{1} h_{2})})^{-1} \left( \left( (L_{g_{1}})_{*g_{2}} \times (L_{h_{1}})_{*h_{2}} \right) \left( \xi_{g_{2}}, \eta_{h_{2}} \right) \right) \\
		&= (f_{(g_{1} g_{2}, h_{1} h_{2})})^{-1} \left( (L_{g_{1}})_{*g_{2}} (\xi_{g_{2}}), (L_{h_{1}})_{*h_{2}} (\eta_{h_{2}}) \right) \\
		&= (f_{(g_{1} g_{2}, h_{1} h_{2})})^{-1} \left( \xi_{g_{1} g_{2}}, \eta_{h_{1} h_{2}} \right) \\
		&= (\xi \oplus \eta)_{(g_{1} g_{2}, h_{1} h_{2})}
	\end{split}
\end{align}

dove abbiamo usato il fatto che i campi di vettori $ \xi $ e $ \eta $ siano singolarmente invarianti a sinistra, i.e. $ \xi \in L(G) $ e $ \eta \in L(H) $, e la commutatività del seguente diagramma\footnote{%
	In generale, il differenziale della traslazione a sinistra non lascia i campi di vettori invariati, dunque l'immagine di questa applicazione è rappresentata da un campo di vettori diverso da quello del dominio, i.e.
	%
	\begin{equation*}
		\xi'_{h} \neq (L_{g})_{*h}(\xi_{h}) \qcomma \xi \in T(G)
	\end{equation*}%
}:

\diagr{%
		{(\xi \oplus \eta)_{(g_{2}, h_{2})}} \arrow[rrrr, "{(L_{g_{1}} \times L_{h_{1}})_{(g_{2},h_{2})}}", maps to]                                                \&  \&  \&  \& {(\xi' \oplus \eta')_{(g_{1} g_{2}, h_{1} h_{2})}} \arrow[ddd, "{f_{(g_{1} g_{2}, h_{1} h_{2})}}", maps to] \\
		\&  \&  \&  \&                                                                                                             \\
		\&  \&  \&  \&                                                                                                             \\
		{(\xi_{g_{2}}, \eta_{h_{2}})} \arrow[rrrr, "(L_{g_{1}})_{*g_{2}} \times (L_{h_{1}})_{*h_{2}}"', maps to] \arrow[uuu, "{(f_{(g_{2},h_{2})})^{-1}}", maps to] \&  \&  \&  \& {(\xi'_{g_{1} g_{2}}, \eta'_{h_{1} h_{2}})} 
		}

da cui si ottiene la seguente uguaglianza

\begin{equation}
	f_{(g_{1} g_{2}, h_{1} h_{2})} \circ (L_{g_{1}} \times L_{h_{1}})_{*(g_{2},h_{2})} \circ (f_{(g,h)})^{-1} = (L_{g_{1}})_{*g_{2}} \times (L_{h_{1}})_{*h_{2}}
\end{equation}

A questo punto abbiamo che i campi di vettori $ \xi \oplus \eta $ sono invarianti a sinistra, il che implica che $ \psi $ sia un isomorfismo (per il ragionamento precedente), i.e.

\begin{equation}
	Lie(G) \oplus Lie(H) \stackrel{iso}{\simeq} Lie(G \times H)
\end{equation}

Il ragionamento vale iterativamente per $ H = \displaystyle\bigoplus_{i=1}^{s-1} G_{i} $, da cui

\begin{equation}
	\bigoplus_{i=1}^{s} Lie(G_{i}) \stackrel{iso}{\simeq} Lie \left( \prod_{i=1}^{s} G_{i} \right) %
	\qcomma \forall s \in \N
\end{equation}

%

\newpage

%

\section{}\label{es3-12}

\begin{tcolorbox}
	Dimostrare che ogni gruppo di Lie è parallelizzabile.
\end{tcolorbox}

qui
