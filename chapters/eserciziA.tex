\section{Funzione $ C^{k}(\R) $ ma non $ C^{k+1}(\R) $}\label{es1-1}

\begin{tcolorbox}
	Per ogni numero naturale $ k \in \N $ costruire una funzione $ C^{k}(\R) $ ma non $ C^{k+1}(\R) $.
\end{tcolorbox}

Per la funzione

\map{f_{k}}
	{\R}{\R}
	{x}{\alpha x^{k(k+2)/(k+1)} + \beta}

per $ \forall \alpha,\beta \in \R $ e con $ k \in \N $, vale $ f_{k} \in C^{k}(\R) $ ma $ f_{k} \notin C^{k+1}(\R) $.

%

\newpage

%

\section{Funzione liscia ma non reale analitica}\label{es1-2}

\begin{tcolorbox}
	Dimostrare che la funzione
	
	\map{f}
		{\R}{\R}
		{x}{%
			\begin{cases}
				e^{\sfrac{-1}{x^{2}}} & x \neq 0\\
				0 & x = 0
			\end{cases}
			}
	
	risulta essere liscia ma non reale analitica.
\end{tcolorbox}

La funzione $ f $ è liscia in quanto, perché lo sia, è necessario che

\begin{equation}
	\pdv[k]{f}{x} \, (0) = \pdv[k]{x} e^{\sfrac{-1}{x^{2}}} \, (0) = 0 \qcomma \forall k \in \N
\end{equation}

e questo è vero poiché

\begin{equation}
	\lim_{x \to 0} \left( \dfrac{e^{\sfrac{-1}{x^{2}}}}{x^{p}} \right) = 0 \qcomma \forall p \in \N %
	\implies%
	\lim_{x \to 0} \left( \pdv[k]{x} \left( e^{\sfrac{-1}{x^{2}}} \right) \right) = 0 \qcomma \forall k \in \N
\end{equation}

La funzione non è però reale analitica perché, in un intervallo aperto qualsiasi di 0 non coincide con il suo sviluppo di Taylor: lo sviluppo di Taylor per la parte dei reali positivi è diversa da 0 per qualsiasi valore di $ x $ non nullo mentre la parte per i reali negativi è identicamente nulla, i.e. preso $ U $ un qualsiasi intorno di 0

\begin{equation}
	\sum_{k=0}^{+\infty} \left( \pdv[k]{x} \left( e^{\sfrac{-1}{x^{2}}} \right) \right) \dfrac{x^{k}}{k!} \neq 0 \qcomma \forall x \in U \setminus \{0\}
\end{equation}

%

\newpage

%

\section{Intervalli diffeomorfi a $ \R $}\label{es1-3}

\begin{tcolorbox}
	Siano $ a,b,c,d \in \R $ tale che $ a<b $. Dimostrare che i seguenti intervalli sono tutti diffeomorfi tra loro e diffeomorfi a $ \R $:
	
	\begin{equation}
		\begin{cases}
			(a,b)\\
			(c,+\infty)\\
			(-\infty,d)
		\end{cases}
	\end{equation}
\end{tcolorbox}

Consideriamo le applicazioni:

\map{f}
	{(a,b)}{(0,1)}
	{x}{\dfrac{x-a}{b-a}}

\map{g}
	{(0,1)}{(c,+\infty)}
	{x}{\dfrac{c}{x}}

\map{h}
	{(0,1)}{(-\infty,d)}
	{x}{\ln(x)-d}

\map{i}
	{(c,+\infty)}{\R}
	{x}{\ln(x-c)}

Queste sono diffeomorfismi in quanto bigezioni lisce con inversa liscia, dunque le loro composizioni sono ancora diffeomorfismi. Le seguenti composizioni delle applicazioni sopraccitate inducono i seguenti diffeomorfismi:

\begin{equation}
	\begin{cases}
		g \circ f \implies (a,b) \simeq (c,+\infty)\\
		h \circ f \implies (a,b) \simeq (-\infty,d)\\
		i \circ g \circ f \implies (a,b) \simeq \R\\
		h \circ g^{-1} \implies (c,+\infty) \simeq (-\infty,d)\\
		i \implies (c,+\infty) \simeq \R\\
		i \circ g \circ h^{-1} \implies (-\infty,d) \simeq \R
	\end{cases}
\end{equation}

%

\newpage

%

\section{Diffeomorfismo tra $ B_{r}(c) $ e $ \R^{n} $}\label{es1-4}

\begin{tcolorbox}
	Dimostrare che l'applicazione
	
	\map{h}
		{B_{1}(0)}{\R^{n}}
		{x}{\left( \dfrac{x^{1}}{\sqrt{1 - \norm{x}^{2}}}, \cdots, \dfrac{x^{n}}{\sqrt{1 - \norm{x}^{2}}} \right)}
	
	definisce un diffeomorfismo tra la palla aperta unitaria centrata nell'origine di $ \R^{n} $ e $ \R^{n} $. Dedurre che la palla aperta di centro $ c \in \R^{n} $ e raggio $ r > 0 $ in $ \R^{n} $ è diffeomorfa a $ \R^{n} $.
\end{tcolorbox}

L'applicazione $ h $ è una bigezione liscia in quanto ogni sua componente è liscia poiché

\begin{equation}
	\pdv[k]{(x^{i})} \left( \dfrac{x^{i}}{\sqrt{ 1-\norm{x}^{2} }} \right) < \infty \qcomma \forall k \in \N, \, \forall x \in B_{1}(0), \, \forall i=1,\dots,n
\end{equation}

La sua inversa

\map{h^{-1}}
	{\R^{n}}{B_{1}(0)}
	{x}{\left( \dfrac{x^{1}}{\sqrt{1 + \norm{x}^{2}}}, \cdots, \dfrac{x^{n}}{\sqrt{1 + \norm{x}^{2}}} \right)}

è ancora liscia per lo stesso motivo, dunque $ h $ induce il diffeomorfismo $ B_{1}(0) \simeq \R^{n} $.\\
Se consideriamo l'applicazione lineare (dunque liscia con inversa liscia e perciò diffeomorfismo)

\map{g}
	{B_{r}(c)}{B_{1}(0)}
	{x}{\dfrac{x-c}{r}}

con $ c = (c^{1},\dots,c^{n}) $, e la componiamo con $ h $, otteniamo

\map{f = h \circ g}
	{B_{r}(c)}{\R^{n}}
	{x}{\left( \dfrac{\dfrac{x^{1} - c^{1}}{r}}{\sqrt{1 + \norm{\dfrac{x-c}{r}}^{2}}}, \cdots, \dfrac{\dfrac{x^{n} - c^{n}}{r}}{\sqrt{1 + \norm{\dfrac{x-c}{r}}^{2}}} \right)}

L'applicazione $ f $ è un diffeomorfismo in quanto composizione di diffeomorfismi, dunque $ f $ induce il diffeomorfismo $ B_{r}(c) \simeq \R^{n} $.

%

\newpage

%

\section{Teorema di Taylor con resto per funzione a due variabili}\label{es1-5}

\begin{tcolorbox}
	Sia $ f \in C^{\infty}(\R^{2}) $. Usando il teorema di Taylor con resto, dimostrare che esistono $ g_{11},g_{12},g_{22} \in C^{\infty}(\R^{2}) $ tali che
	
	\begin{equation}
		f(x,y) = f(0,0) + x \, \dfrac{\partial f}{\partial x} (0,0) + y \, \dfrac{\partial f}{\partial y} (0,0) + x^{2} \, g_{11}(x,y) + x y \, g_{12}(x,y) + y^{2} \, g_{22}(x,y)
	\end{equation}
\end{tcolorbox}

Dal teorema di Taylor con resto, se $ f \in C^{\infty} (\R^{2}) $ ($ \R^{2} $ è stellato rispetto all'origine), abbiamo che

\begin{equation}
	\E g_{i_{1} \cdots i_{k}} \in C^{\infty} (\R^{2})
\end{equation}

definite come

\begin{equation}
	g_{i_{1} \cdots i_{k}} (0,0) \doteq \dfrac{1}{k!} \dfrac{\partial^{k} f}{\partial x^{i_{1}} \cdots \partial x^{i_{k}}} (0,0)
\end{equation}

tali che

\begin{equation}
	f(x,y) = f(0,0) + \sum_{m=1}^{k} \sum_{\substack{i_{1},\dots,i_{k}=1 \\ {i_{k}} > \cdots > i_{1}}}^{m} g_{i_{1} \cdots i_{k}} (x,y) \prod_{j=1}^{k} x^{i_{j}} \qcomma \forall k \in \N
\end{equation}

Espandendo quest'ultima forma per $ k=1 $ otteniamo

\begin{align}
	\begin{split}
		f(x,y) &= f(0,0) + x \, g_{1} (x,y) + y \, g_{2} (x,y)\\
		&= f(0,0) + x \, g_{1} (0,0) + y \, g_{2} (0,0) + x^{2} \, g_{11}(x,y) + x y \, g_{12}(x,y) + y^{2} \, g_{22}(x,y)\\
		&= f(0,0) + x \, \dfrac{\partial f}{\partial x} (0,0) + y \, \dfrac{\partial f}{\partial y} (0,0) + x^{2} \, g_{11}(x,y) + x y \, g_{12}(x,y) + y^{2} \, g_{22}(x,y)
	\end{split}
\end{align}

dove gli ultimi 3 termini indicano il resto.

%

\newpage

%

\section{Funzione liscia tramite incollamento}\label{es1-6}

\begin{tcolorbox}
	Sia $ f \in C^{\infty} (\R^{2}) $ tale che
	
	\begin{equation}
		f(0,0) = \pdv{f}{x} \, (0,0) = \pdv{f}{y} \, (0,0) = 0
	\end{equation}
	
	Sia l'applicazione
	
	\map{g}
		{\R^{2}}{\R}
		{(t,u)}{%
				\begin{cases}
					\dfrac{f(t,tu)}{t} & t \neq 0\\\\
					0 & t = 0
				\end{cases}
				}
	
	Dimostrare che $ g \in C^{\infty}(\R^{2}) $.
\end{tcolorbox}

qui

%

\newpage

%

\section{$ C_{p}^{\infty}(\R^{n}) $ come algebra commutativa e unitaria}\label{es1-7}

\begin{tcolorbox}
	Dimostrare che l'insieme $ C_{p}^{\infty}(\R^{n}) $ dei germi delle funzioni lisce intorno a $ p \in \R^{n} $ con le operazioni di somma e di prodotto definite negli appunti è un'algebra commutativa e unitaria.
\end{tcolorbox}

L'algebra $ A = (C_{p}^{\infty}(\R^{n}),+,\cdot) $ ha le operazioni definite come segue:

\map{+}
	{A \times A}{A}
	{([(f,U)],[(g,V)])}{[(f+g,U \cap V)]}

\map{\cdot}
	{A \times A}{A}
	{([(f,U)],[(g,V)])}{[(f g,U \cap V)]}

Perché sia effettivamente un'algebra, verifichiamo che sia distributiva e omogenea.\\
Per la distributività sinistra:

\begin{align}
	\begin{split}
		([(f,U)] + [(g,V)]) \cdot [(h,W)] &= [(f+g,U \cap V)] \cdot [(h,W)]\\
		&= [((f+g) h,U \cap V \cap W)]\\
		&= [(fh + gh,U \cap V \cap W)]\\
		&= [(fh,U \cap W)] + [(gh,V \cap W)]\\
		&= [(f,U)] \cdot [(h,W)] + [(g,V)] \cdot [(h,W)]
	\end{split}
\end{align}

per $ \forall [(f,U)], [(g,V)], [(h,W)] \in C_{p}^{\infty}(\R^{n}) $.\\
La distributività destra deriva immediatamente dalla distributività sinistra e dalla commutatività (condizione non necessaria per un'algebra): quest'ultima può essere verificata tramite i seguenti passaggi

\begin{align}
	\begin{split}
		[(f,U)] + [(g,V)] &= [(f+g,U \cap V)]\\
		&= [(g+f,V \cap U)]\\
		&= [(g,V)] + [(f,U)]\\\\
		%
		[(f,U)] \cdot [(g,V)] &= [(fg,U \cap V)]\\
		&= [(gf,V \cap U)]\\
		&= [(g,V)] \cdot [(f,U)]
	\end{split}
\end{align}

per $ \forall [(f,U)], [(g,V)] \in C_{p}^{\infty}(\R^{n}) $.\\
Per l'omogeneità:

\begin{align}
	\begin{split}
		\lambda ([(f,U)] \cdot [(g,V)]) &= \lambda [(fg,U \cap V)]\\
		&= [(\lambda fg,V \cap U)]\\
		&= [(\lambda f,U)] \cdot [(g,V)]\\
		&= [(f,U)] \cdot [(\lambda g,V)]
	\end{split}
\end{align}

per $ \forall [(f,U)], [(g,V)] \in C_{p}^{\infty}(\R^{n}) $ e $ \forall \lambda \in \R $.\\
Infine l'unitarietà, i.e.

\begin{equation}
	\E e = [(1,U)] \in C_{p}^{\infty}(\R^{n}) \mid [(f,U)] \cdot e = e \cdot [(f,U)] = [(f,U)] \qcomma \forall [(f,U)] \in C_{p}^{\infty}(\R^{n})
\end{equation}

può essere verificata tramite i seguenti passaggi:

\begin{align}
	\begin{split}
		[(f,U)] \cdot [(1,U)] &= [(f \cdot 1,U \cap U)]\\
		&= [(1 \cdot f,U \cap U)]\\
		&= [(1,U)] \cdot [(f,U)]\\
		&= [(f,U)]
	\end{split}
\end{align}

%

\newpage

%

\section{$ \der_{p}(C_{p}^{\infty}(\R^{n})) $ come spazio vettoriale su $ \R $}\label{es1-8}

\begin{tcolorbox}
	Dimostrare che l'insieme $ \der_{p}(C_{p}^{\infty}(\R^{n})) $ delle derivazioni puntuali con le operazioni definite negli appunti è uno spazio vettoriale su $ \R $.
\end{tcolorbox}

Per dimostrare che $ \der_{p}(C_{p}^{\infty}(\R^{n})) $ sia uno spazio vettoriale su $ \R $ è necessario che le operazioni di somma tra derivazioni e moltiplicazione per scalari rispettino i seguenti 8 assiomi:

\begin{equation}
	\begin{cases}
		D_{v} + (D_{w} + D_{x}) = (D_{v} + D_{w}) + D_{x} & \text{ 1. associatività (somma) }\\
		%
		D_{v} + D_{w} = D_{w} + D_{v} & \text{ 2. commutatività (somma) }\\
		%
		\E 0 \in \der_{p}(C_{p}^{\infty}(\R^{n})) \, \mid \, D_{v} + 0 = D_{v} & \text{ 3. elemento neutro (somma) }\\
		%
		\E - D_{v} \in \der_{p}(C_{p}^{\infty}(\R^{n})) \, \mid \, D_{v} + (- D_{v}) = 0 & \text{ 4. inverso (somma) }\\
		%
		\alpha (\beta D_{v}) = (\alpha \beta) D_{v} & \text{ 5. compatibilità (moltiplicazione) }\\
		%
		\E 1 \in \R \, \mid \, 1 D_{v} = D_{v} & \text{ 6. elemento neutro (moltiplicazione) }\\
		%
		(\alpha + \beta) D_{v} = \alpha D_{v} + \beta D_{v} & \text{ 7. distributività (somma vettoriale) }\\
		%
		\alpha (D_{v} + D_{w}) = \alpha D_{v} + \alpha D_{w} & \text{ 8. distributività (somma scalare) }
	\end{cases}
\end{equation}

per $ \forall D_{v}, D_{w}, D_{x} \in \der_{p}(C_{p}^{\infty}(\R^{n})) $ e $ \forall \alpha, \beta \in \R $.\\
Per dimostrare queste proprietà consideriamo un qualunque $ [(f,U)] \in C_{p}^{\infty}(\R^{n}) $ e applichiamo a questo le derivazioni:

\begin{enumerate}
	\item Associatività (somma)
	
	\begin{align}
		\begin{split}
			( D_{v} + (D_{w} + D_{x}) ) ([(f,U)]) &= D_{v} ([(f,U)]) + (D_{w} + D_{x}) ([(f,U)])\\
			&= D_{v} ([(f,U)]) + D_{w} ([(f,U)]) + D_{x} ([(f,U)])\\
			&= (D_{v} + D_{w}) ([(f,U)]) + D_{x} ([(f,U)])\\
			&= ( (D_{v} + D_{w}) + D_{x} ) ([(f,U)])
		\end{split}
	\end{align}
	
	\item Commutatività (somma)
	
	\begin{align}
		\begin{split}
			(D_{v} + D_{w}) ([(f,U)]) &= D_{v} ([(f,U)]) + D_{w} ([(f,U)])\\
			&= D_{w} ([(f,U)]) + D_{v} ([(f,U)])\\
			&= (D_{w} + D_{v}) ([(f,U)])
		\end{split}
	\end{align}
	
	dove nel secondo passaggio abbiamo usato la commutatività della somma in $ \R $
	
	\item Elemento neutro (somma)
	
	\map{0}
		{C_{p}^{\infty}(\R^{n})}{\R}
		{[(f,U)]}{0}
	
	per $ \forall [(f,U)] \in C_{p}^{\infty}(\R^{n}) $, dunque
	
	\begin{align}
		\begin{split}
			(D_{v} + 0) ([(f,U)]) &= D_{v} ([(f,U)]) + 0 ([(f,U)])\\
			&= D_{v} ([(f,U)]) + 0\\
			&= D_{v} ([(f,U)])
		\end{split}
	\end{align}
	
	\item Inverso (somma)
	
	\map{- D_{v}}
		{C_{p}^{\infty}(\R^{n})}{\R}
		{[(f,U)]}{- \sum_{i=1}^{n} \pdv{f}{x^{i}} \, (p) \, v^{i}}
	
	dunque
	
	\begin{align}
		\begin{split}
			(D_{v} + (- D_{v})) ([(f,U)]) &= D_{v} ([(f,U)]) + (- D_{v}) ([(f,U)])\\
			&= \sum_{i=1}^{n} \pdv{f}{x^{i}} \, (p) \, v^{i} + \left( - \sum_{i=1}^{n} \pdv{f}{x^{i}} \, (p) \, v^{i} \right)\\
			&= 0
		\end{split}
	\end{align}
	
	\item Compatibilità (moltiplicazione)
	
	\begin{align}
		\begin{split}
			(\alpha (\beta D_{v})) ([(f,U)]) &= \alpha (\beta D_{v}) ([(f,U)])\\
			&= \alpha D_{v} ([(\beta f,U)])\\
			&= \alpha \beta D_{v} ([(f,U)])\\
			&= (\alpha \beta) D_{v} ([(f,U)])
		\end{split}
	\end{align}
	
	\item Elemento neutro (moltiplicazione)
	
	\begin{align}
		\begin{split}
			(1 D_{v}) ([(f,U)]) &= D_{v} ([(1 f,U)])\\
			&= D_{v} ([(f,U)])
		\end{split}
	\end{align}
	
	\item Distributività (somma vettoriale)
	
	\begin{align}
		\begin{split}
			(\alpha + \beta) D_{v} ([(f,U)]) &= D_{v} ([((\alpha + \beta) f,U)])\\
			&= D_{v} ([(\alpha f + \beta f,U)])\\
			&= \alpha D_{v} ([(f,U)]) + \beta D_{v} ([(f,U)])\\
		\end{split}
	\end{align}
	
	\item Distributività (somma scalare)
	
	\begin{align}
		\begin{split}
			\alpha (D_{v} + D_{w}) ([(f,U)]) &= (D_{v} + D_{w}) ([(\alpha f,U)])\\
			&= D_{v} ([(\alpha f,U)]) + D_{w} ([(\alpha f,U)])\\
			&= \alpha D_{v} ([(f,U)]) + \alpha D_{w} ([(f,U)])
		\end{split}
	\end{align}
\end{enumerate}

Tutte queste proprietà sono valide per $ \forall D_{v}, D_{w}, D_{x} \in \der_{p}(C_{p}^{\infty}(\R^{n})) $ e $ \forall \alpha, \beta \in \R $.

%

\newpage

%

\section{$ \chi(U) $ come spazio vettoriale su $ \R $ e $ C^{\infty} $-modulo}\label{es1-9}

\begin{tcolorbox}
	Dimostrare che l'insieme dei campi di vettori lisci $ \chi(U) $ su un aperto $ U \subset \R^{n} $ con le operazioni definite negli appunti è uno spazio vettoriale su $ \R $ e un $ C^{\infty} $-modulo.
\end{tcolorbox}

\paragraph{Spazio vettoriale su $ \R $}

Per dimostrare che $ \chi(U) $ sia uno spazio vettoriale su $ \R $ è necessario che le operazioni di somma tra campi di vettori e moltiplicazione per scalari rispettino i seguenti 8 assiomi:

\begin{equation}
	\begin{cases}
		X + (Y + Z) = (X + Y) + Z & \text{ 1. associatività (somma) }\\
		%
		X + Y = Y + X & \text{ 2. commutatività (somma) }\\
		%
		\E 0 \in \chi(U) \, \mid \, X + 0 = X & \text{ 3. elemento neutro (somma) }\\
		%
		\E - X \in \chi(U) \, \mid \, X + (- X) = 0 & \text{ 4. inverso (somma) }\\
		%
		\alpha (\beta X) = (\alpha \beta) X & \text{ 5. compatibilità (moltiplicazione) }\\
		%
		\E 1 \in \R \, \mid \, 1 X = X & \text{ 6. elemento neutro (moltiplicazione) }\\
		%
		(\alpha + \beta) X = \alpha X + \beta X & \text{ 7. distributività (somma vettoriale) }\\
		%
		\alpha (X + Y) = \alpha X + \alpha Y & \text{ 8. distributività (somma scalare) }
	\end{cases}
\end{equation}

per $ \forall X, Y, Z \in \chi(U) $ e $ \forall \alpha, \beta \in \R $.\\
Ricordiamo che le operazioni sono definite come:

\begin{align}
	\begin{split}
		(X + Y)_{p} &\doteq X_{p} + Y_{p}\\
		(\alpha X)_{p} &\doteq \alpha X_{p}
	\end{split}
\end{align}

per $ \forall X, Y \in \chi(U) $, $ \forall \alpha \in \R $ e $ \forall p \in U \subset \R^{n} $, dove i campi di vettori saranno:

\begin{equation}
	X = \sum_{i=1}^{n} a^{i} \pdv{x^{i}} \qcomma Y = \sum_{i=1}^{n} b^{i} \pdv{x^{i}}
\end{equation}

con $ a_{i}, b_{i} \in C^{\infty}(U) $.\\
Per dimostrare dunque queste proprietà, valutiamo i campi di vettori in un qualunque $ p \in U \subset \R^{n} $:

\begin{enumerate}
	\item Associatività (somma)
	
	\begin{align}
		\begin{split}
			(X + (Y + Z))_{p} &= (X + Y)_{p} + Z_{p}\\
			&= X_{p} + Y_{p} + Z_{p}\\
			&= X_{p} + (Y + Z)_{p}\\
			&= (X + (Y + Z))_{p}
		\end{split}
	\end{align}
	
	\item Commutatività (somma)
	
	\begin{align}
		\begin{split}
			(X + Y)_{p} &= X_{p} + Y_{p}\\
			&= \sum_{i=1}^{n} a^{i} (p) \eval{ \pdv{x^{i}} }_{p} + \sum_{i=1}^{n} b^{i} (p) \eval{ \pdv{x^{i}} }_{p}\\
			&= \sum_{i=1}^{n} b^{i} (p) \eval{ \pdv{x^{i}} }_{p} + \sum_{i=1}^{n} a^{i} (p) \eval{ \pdv{x^{i}} }_{p}\\
			&= Y_{p} + X_{p}\\
			&= (Y + X)_{p}
		\end{split}
	\end{align}
	
	\item Elemento neutro (somma)
	
	\map{0}
		{U}{\bigsqcup_{p \in U} T_{p} (\R^{n})}
		{p}{%
			0_{p} = \sum_{i=1}^{n} 0 \eval{ \pdv{x^{i}} }_{p}\\
			&\stackrel{\R^{n}}{\mapsto} (0, \dots, 0)%
		}
	
	dunque
	
	\begin{align}
		\begin{split}
			(X + 0)_{p} &= X_{p} + 0_{p}\\
			&= \sum_{i=1}^{n} a^{i} (p) \eval{ \pdv{x^{i}} }_{p} + \sum_{i=1}^{n} 0 \eval{ \pdv{x^{i}} }_{p}\\
			&= \sum_{i=1}^{n} (a^{i} (p) + 0) \eval{ \pdv{x^{i}} }_{p}\\
			&= \sum_{i=1}^{n} a^{i} (p) \eval{ \pdv{x^{i}} }_{p}\\
			&= X_{p}
		\end{split}
	\end{align}
	
	\item Inverso (somma)
	
	\map{- X}
		{U}{\bigsqcup_{p \in U} T_{p} (\R^{n})}
		{p}{\sum_{i=1}^{n} (- a^{i} (p)) \eval{ \pdv{x^{i}} }_{p}}
	
	dunque
	
	\begin{align}
		\begin{split}
			(X + (- X))_{p} &= X_{p} + (- X)_{p}\\
			&= \sum_{i=1}^{n} a^{i} (p) \eval{ \pdv{x^{i}} }_{p} + \sum_{i=1}^{n} (- a^{i} (p)) \eval{ \pdv{x^{i}} }_{p}\\
			&= \sum_{i=1}^{n} (a^{i} (p) - a^{i} (p)) \eval{ \pdv{x^{i}} }_{p}\\
			&= \sum_{i=1}^{n} 0 \eval{ \pdv{x^{i}} }_{p}\\
			&= 0_{p}
		\end{split}
	\end{align}
	
	\item Compatibilità (moltiplicazione)
	
	\begin{align}
		\begin{split}
			(\alpha (\beta X))_{p} &= \alpha (\beta X)_{p}\\
			&= \alpha \beta X_{p}\\
			&= (\alpha \beta) X_{p}\\
			&= ((\alpha \beta) X)_{p}
		\end{split}
	\end{align}
	
	\item Elemento neutro (moltiplicazione)
	
	\begin{align}
		\begin{split}
			(1 X_{p}) &= 1 X_{p}\\
			&= 1 \sum_{i=1}^{n} a^{i} (p) \eval{ \pdv{x^{i}} }_{p}\\
			&= \sum_{i=1}^{n} (1 a^{i} (p)) \eval{ \pdv{x^{i}} }_{p}\\
			&= \sum_{i=1}^{n} a^{i} (p) \eval{ \pdv{x^{i}} }_{p}\\
			&= X_{p}
		\end{split}
	\end{align}
	
	\item Distributività (somma vettoriale)
	
	\begin{align}
		\begin{split}
			(\alpha (X + Y))_{p} &= \alpha (X + Y)_{p}\\
			&= \alpha (X_{p} + Y_{p})\\
			&= \alpha \left( \sum_{i=1}^{n} a^{i} (p) \eval{ \pdv{x^{i}} }_{p} + \sum_{i=1}^{n} b^{i} (p) \eval{ \pdv{x^{i}} }_{p} \right)\\
			&= \alpha \sum_{i=1}^{n} a^{i} (p) \eval{ \pdv{x^{i}} }_{p} + \alpha \sum_{i=1}^{n} b^{i} (p) \eval{ \pdv{x^{i}} }_{p}\\
			&= \alpha X_{p} + \alpha Y_{p}\\
			&= (\alpha X)_{p} + (\alpha Y)_{p}\\
			&= (\alpha X + \alpha Y)_{p}
		\end{split}
	\end{align}
	
	\item Distributività (somma scalare)
	
	\begin{align}
		\begin{split}
			((\alpha + \beta) X)_{p} &= (\alpha + \beta) X_{p}\\
			&= (\alpha + \beta) \sum_{i=1}^{n} a^{i} (p) \eval{ \pdv{x^{i}} }_{p}\\
			&= \alpha \sum_{i=1}^{n} a^{i} (p) \eval{ \pdv{x^{i}} }_{p} + \beta \sum_{i=1}^{n} a^{i} (p) \eval{ \pdv{x^{i}} }_{p}\\
			&= \alpha X_{p} + \beta X_{p}\\
			&= (\alpha X)_{p} + (\beta X)_{p}\\
			&= (\alpha X + \beta X)_{p} 
		\end{split}
	\end{align}
\end{enumerate}

Tutte queste proprietà sono valide per $ \forall X, Y, Z \in \chi(U) $ e $ \forall \alpha, \beta \in \R $.

\paragraph{$ C^{\infty} $-modulo}

Sia l'applicazione

\map{\cdot}
	{C^{\infty}(U) \times \chi(U)}{\chi(U)}
	{(f,X)}{f X}

Per dimostrare che $ (\chi(U),+) $ sia un $ C^{\infty} $-modulo è necessario che siano verificate queste proprietà sia a sinistra che a destra:

\begin{equation}
	\begin{cases}
		1_{C^{\infty}(U)} X = X & \text{ 1. elemento neutro (somma) }\\
		f (g X) = (f g) X & \text{ 2. compatibilità (moltiplicazione) }\\
		f (X+Y) = f X + f Y & \text{ 3. distributività (somma vettoriale) }\\
		(f+g) X = f X + g X & \text{ 4. distributività (somma scalare) }
	\end{cases}
\end{equation}

per $ \forall f,g \in C^{\infty}(U) $ e $ \forall X,Y \in \chi(U) $. Siccome la moltiplicazione per funzione è commutativa è sufficiente dimostrare che $ (\chi(U),+) $ sia un $ C^{\infty}(U) $-modulo sinistro (o destro) per dimostrare che sia $ C^{\infty}(U) $-modulo.\\
Dimostriamo dunque le proprietà riportate sopra, ancora una volta valutando i campi di vettori in un qualunque $ p \in U \subset \R^{n} $:

\begin{enumerate}
	\item Elemento neutro (somma)
	
	\map{1_{C^{\infty}(U)}}
		{U}{\R}
		{p}{1}
	
	dunque
	
	\begin{align}
		\begin{split}
			(1_{C^{\infty}(U)} X)_{p} &= 1_{C^{\infty}(U)} (p) X_{p}\\
			&= 1 \sum_{i=1}^{n} a^{i} (p) \eval{ \pdv{x^{i}} }_{p}\\
			&= \sum_{i=1}^{n} (1 a^{i} (p)) \eval{ \pdv{x^{i}} }_{p}\\
			&= \sum_{i=1}^{n} a^{i} (p) \eval{ \pdv{x^{i}} }_{p}\\
			&= X_{p}
		\end{split}
	\end{align}
	
	\item Compatibilità (moltiplicazione)
	
	\begin{align}
		\begin{split}
			(f (g X))_{p} &= f (p) (g X)_{p}\\
			&= f (p) g (p) X_{p}\\
			&= (f g) (p) X_{p}\\
			&= ((f g) X)_{p}
		\end{split}
	\end{align}
	
	\item Distributività (somma vettoriale)
	
	\begin{align}
		\begin{split}
			(f (X + Y))_{p} &= f (p) (X + Y)_{p}\\
			&= f (p) (X_{p} + Y_{p})\\
			&= f (p) X_{p} + f (p) Y_{p}\\
			&= (f X)_{p} + (f Y)_{p}\\
			&= (f X + f Y)_{p}
		\end{split}
	\end{align}
	
	\item Distributività (somma scalare)
	
	\begin{align}
		\begin{split}
			((f + g) X)_{p} &= (f + g) (p) X_{p}\\
			&= (f (p) + g (p)) X_{p}\\
			&= f (p) X_{p} + g (p) X_{p}\\
			&= (f X)_{p} + (g X)_{p}\\
			&= (f X + g X)_{p}
		\end{split}
	\end{align}
\end{enumerate}

Tutte queste proprietà sono valide per $ \forall f,g \in C^{\infty}(U) $ e $ \forall X,Y \in \chi(U) $.

%

\newpage

%

\section{$ \der(A) $ come spazio vettoriale su $ \K $}\label{es1-10}

\begin{tcolorbox}
	Sia $ A $ un'algebra su un campo $ \K $. Dimostrare che le operazioni
	
	\begin{equation}
		\begin{cases}
			(D_{1}+D_{2})(a) = D_{1}(a) + D_{2}(a)\\
			(\lambda D)(a) = \lambda D(a)
		\end{cases}
	\end{equation}
	
	per $ \forall \lambda \in \K $ e $ \forall D_{1},D_{2},D \in \der(A) $ dotano $ \der(A) $ della struttura di spazio vettoriale su $ \K $.
\end{tcolorbox}

Per dimostrare che $ \der(A) $ sia uno spazio vettoriale su un campo $ \K $ è necessario che le operazioni di somma tra derivazioni e moltiplicazione per scalari rispettino i seguenti 8 assiomi:

\begin{equation}
	\begin{cases}
		D_{1} + (D_{2} + D_{3}) = (D_{1} + D_{2}) + D_{3} & \text{ 1. associatività (somma) }\\
		%
		D_{1} + D_{2} = D_{2} + D_{1} & \text{ 2. commutatività (somma) }\\
		%
		\E 0 \in \der(A)) \, \mid \, D + 0 = D & \text{ 3. elemento neutro (somma) }\\
		%
		\E - D \in \der(A) \, \mid \, D + (- D) = 0 & \text{ 4. inverso (somma) }\\
		%
		\alpha (\beta D) = (\alpha \beta) D & \text{ 5. compatibilità (moltiplicazione) }\\
		%
		\E \eta \in \K \, \mid \, \eta D = D & \text{ 6. elemento neutro (moltiplicazione) }\\
		%
		(\alpha + \beta) D = \alpha D + \beta D & \text{ 7. distributività (somma vettoriale) }\\
		%
		\alpha (D_{1} + D_{2}) = \alpha D_{1} + \alpha D_{2} & \text{ 8. distributività (somma scalare) }
	\end{cases}
\end{equation}

per $ \forall D_{1}, D_{2}, D_{3}, D \in \der(A) $ e $ \forall \alpha, \beta \in \K $.\\
Per dimostrare queste proprietà consideriamo un qualunque $ a \in A $ e applichiamo a questo le derivazioni:

\begin{enumerate}
	\item Associatività (somma)
	
	\begin{align}
		\begin{split}
			( D_{1} + (D_{2} + D_{3}) ) (a) &= D_{1} (a) + (D_{2} + D_{3}) (a)\\
			&= D_{1} (a) + D_{2} (a) + D_{3} (a)\\
			&= (D_{1} + D_{2}) (a) + D_{3} (a)\\
			&= ( (D_{1} + D_{2}) + D_{3} ) (a)
		\end{split}
	\end{align}
	
	\item Commutatività (somma)
	
	\begin{align}
		\begin{split}
			(D_{1} + D_{2}) (a) &= D_{1} (a) + D_{2} (a)\\
			&= D_{2} (a) + D_{1} (a)\\
			&= (D_{2} + D_{1}) (a)
		\end{split}
	\end{align}
	
	dove nel secondo passaggio abbiamo usato la commutatività della somma dell'algebra ereditata dallo spazio vettoriale che la compone
	
	\item Elemento neutro (somma)
	
	\map{0}
		{A}{A}
		{a}{0}
	
	dove
	
	\begin{equation}
		a + 0 = a \qcomma \forall a \in A
	\end{equation}
	
	dunque
	
	\begin{align}
		\begin{split}
			(D + 0) (a) &= D (a) + 0 (a)\\
			&= D (a) + 0\\
			&= D (a)
		\end{split}
	\end{align}
	
	\item Inverso (somma)
	
	\map{- D}
		{A}{A}
		{a}{- D (a)}
	
	dunque
	
	\begin{align}
		\begin{split}
			(D + (- D)) (a) &= D (a) + (- D) (a)\\
			&= D (a) + - D (a)\\
			&= 0
		\end{split}
	\end{align}
	
	\item Compatibilità (moltiplicazione)
	
	\begin{align}
		\begin{split}
			(\alpha (\beta D)) (a) &= \alpha (\beta D) (a)\\
			&= \alpha \beta D (a)\\
			&= (\alpha \beta) D (a)\\
			&= ((\alpha \beta) D) (a)
		\end{split}
	\end{align}
	
	\item Elemento neutro (moltiplicazione)
	
	\begin{align}
		\begin{split}
			(\eta D) (a) &= \eta D (a)\\
			&= D (\eta a)\\
			&= D (a)
		\end{split}
	\end{align}
	
	dove abbiamo usato il fatto che lo spazio vettoriale che compone l'algebra è sullo stesso campo $ \K $ rispetto a quest'ultima
	
	\item Distributività (somma vettoriale)
	
	\begin{align}
		\begin{split}
			((\alpha + \beta) D) (a) &= (\alpha + \beta) D (a)\\
			&= \alpha D (a) + \beta D (a)\\
			&= (\alpha D) (a) + (\beta D) (a)\\
			&= (\alpha D + \beta D) (a)
		\end{split}
	\end{align}
	
	\item Distributività (somma scalare)
	
	\begin{align}
		\begin{split}
			(\alpha (D_{1} + D_{2})) (a) &= \alpha (D_{1} + D_{2}) (a)\\
			&= \alpha (D_{1} (a) + D_{2} (a))\\
			&= \alpha D_{1} (a) + \alpha D_{2} (a)\\
			&= (\alpha D_{1}) (a) + (\alpha D_{2}) (a)\\
			&= (\alpha D_{1} + \alpha D_{2}) (a)
		\end{split}
	\end{align}
\end{enumerate}

Tutte queste proprietà sono valide per $ \forall D_{1}, D_{2}, D_{3}, D \in \der(A) $ e $ \forall \alpha, \beta \in \K $.

%

\newpage

%

\section{Commutatore come derivazione}\label{es1-11}

\begin{tcolorbox}
	Siano $ D_{1} $ e $ D_{2} $ due derivazioni di un'algebra $ A $ su un campo $ \K $, i.e. $ D_{1},D_{2} \in Der(A) $. Mostrare che $ D_{1} \circ D_{2} $ non è necessariamente una derivazione di $ A $ mentre
	
	\begin{equation}
		D_{1} \circ D_{2} - D_{2} \circ D_{1} \in Der(A)
	\end{equation}
\end{tcolorbox}

Perché $ D_{1} \circ D_{2} $ sia una derivazione deve, in particolare, soddisfare la regola di Leibniz, ma questo non è verificato:

\begin{align}
	\begin{split}
		(D_{1} \circ D_{2})(a \cdot b) &= D_{1}(D_{2}(a \cdot b))\\
		&= D_{1}( D_{2}(a) \cdot b + a \cdot D_{2}(b) )\\
		&= D_{1}(D_{2}(a)) \cdot b + D_{2}(a) \cdot D_{1}(b) + D_{1}(a) \cdot D_{2}(b) + a \cdot D_{1}(D_{2}(b))\\
		&= (D_{1} \circ D_{2})(a) \cdot b + a \cdot (D_{1} \circ D_{2})(b) + D_{2}(a) \cdot D_{1}(b) + D_{1}(a) \cdot D_{2}(b)\\
		&\neq (D_{1} \circ D_{2})(a) \cdot b + a \cdot (D_{1} \circ D_{2})(b)
	\end{split}
\end{align}

Mentre per la combinazione $ D_{1} \circ D_{2} - D_{2} \circ D_{1} $ questa prescrizione è verificata:

\begin{align}
	\begin{split}
		(D_{1} \circ D_{2} - D_{2} &\circ D_{1})(a \cdot b) = D_{1}(D_{2}(a \cdot b)) - D_{2}(D_{1}(a \cdot b))\\
		&= (D_{1} \circ D_{2})(a) \cdot b + a \cdot (D_{1} \circ D_{2})(b) + D_{2}(a) \cdot D_{1}(b) + D_{1}(a) \cdot D_{2}(b) +\\
		& \hal - ((D_{2} \circ D_{1})(a) \cdot b + a \cdot (D_{2} \circ D_{1})(b) + D_{1}(a) \cdot D_{2}(b) + D_{2}(a) \cdot D_{1}(b))\\
		%
		&= (D_{1} \circ D_{2})(a) \cdot b + a \cdot (D_{1} \circ D_{2})(b) + \cancel{ D_{2}(a) \cdot D_{1}(b) } + \cancel{ D_{1}(a) \cdot D_{2}(b) } +\\
		& \hal - (D_{2} \circ D_{1})(a) \cdot b - a \cdot (D_{2} \circ D_{1})(b) - \cancel{ D_{1}(a) \cdot D_{2}(b) } - \cancel{ D_{2}(a) \cdot D_{1}(b) }\\
		%
		&= (D_{1} \circ D_{2} - D_{2} \circ D_{1})(a) \cdot b + a \cdot (D_{1} \circ D_{2} - D_{2} \circ D_{1})(b)
	\end{split}
\end{align}

dove nell'ultimo passaggio abbiamo semplificato due coppie di fattori avvalendoci della commutatività dell'operazione $ \cdot : A \to A $ dell'algebra $ A $, dunque $ D_{1} \circ D_{2} - D_{2} \circ D_{1} \in Der(A) $.

